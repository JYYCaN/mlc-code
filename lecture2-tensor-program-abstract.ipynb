{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm.script import tir as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造一个执行两向量加法的张量程序。\n",
    "- TVMScript 是一种让我们能以 Python 抽象语法树的形式来表示张量程序的方式。\n",
    "- 这段代码并不实际对应一个 Python 程序，而是对应一个机器学习编译过程中的张量程序。\n",
    "- TVMScript 的语言设计是为了与 Python 语法所对应，并在 Python 语法的基础上增加了能够帮助程序分析与变换的额外结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyModule:\n",
    "    @T.prim_func\n",
    "    # 定义多维数组用于存储变量\n",
    "    def main(A: T.Buffer[128, \"float32\"],\n",
    "             B: T.Buffer[128, \"float32\"],\n",
    "             C: T.Buffer[128, \"float32\"]):\n",
    "        # extra annotations for the function\n",
    "        T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
    "        for i in range(128):\n",
    "            with T.block(\"C\"):\n",
    "                # declare a data parallel iterator on spatial domain\n",
    "                vi = T.axis.spatial(128, i)\n",
    "                C[vi] = A[vi] + B[vi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MyModule 是 IRModule 数据结构的一个实例，是一组张量函数的集合。\n",
    "- 我们可以通过 script 函数得到这个 IRModule 的 TVMScript 表示。这个函数对于在一步步程序变换间检查 IRModule 而言非常有帮助。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.ir.module.IRModule'>\n",
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @tir.prim_func\n",
      "    def func(A: tir.Buffer[128, \"float32\"], B: tir.Buffer[128, \"float32\"], C: tir.Buffer[128, \"float32\"]) -> None:\n",
      "        # function attr dict\n",
      "        tir.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        # body\n",
      "        # with tir.block(\"root\")\n",
      "        for i in tir.serial(128):\n",
      "            with tir.block(\"C\"):\n",
      "                vi = tir.axis.spatial(128, i)\n",
      "                tir.reads(A[vi], B[vi])\n",
      "                tir.writes(C[vi])\n",
      "                C[vi] = A[vi] + B[vi]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(type(MyModule))\n",
    "print(MyModule.script())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在任何时刻，我们都可以通过 build 将一个 IRModule 转化为可以执行的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.driver.build_module.OperatorModule"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_mod = tvm.build(MyModule, target=\"llvm\") # cpu\n",
    "type(rt_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在编译后，mod 包含了一组可以执行的函数。我们可以通过这些函数的名字拿到对应的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.runtime.packed_func.PackedFunc at 0x7fb0f474ec40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func = rt_mod[\"main\"]\n",
    "func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tvm.nd.array(np.arange(128, dtype=\"float32\"))\n",
    "b = tvm.nd.array(np.ones(128, dtype=\"float32\"))\n",
    "c = tvm.nd.array(np.empty((128,), dtype=\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      " 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      " 126. 127.] [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.] [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "func(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.\n",
      "  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.\n",
      "  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.\n",
      "  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.\n",
      "  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.  84.\n",
      "  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.  98.\n",
      "  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111. 112.\n",
      " 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125. 126.\n",
      " 127. 128.]\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量程序变换\n",
    "现在我们开始变换张量程序。一个张量程序可以通过一个辅助的名为调度（schedule）的数据结构得到变换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.tir.schedule.schedule.Schedule"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch = tvm.tir.Schedule(MyModule)\n",
    "type(sch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先尝试拆分循环。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @tir.prim_func\n",
      "    def func(A: tir.Buffer[128, \"float32\"], B: tir.Buffer[128, \"float32\"], C: tir.Buffer[128, \"float32\"]) -> None:\n",
      "        # function attr dict\n",
      "        tir.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        # body\n",
      "        # with tir.block(\"root\")\n",
      "        for i_0, i_1, i_2 in tir.grid(8, 4, 4):\n",
      "            with tir.block(\"C\"):\n",
      "                vi = tir.axis.spatial(128, i_0 * 16 + i_1 * 4 + i_2)\n",
      "                tir.reads(A[vi], B[vi])\n",
      "                tir.writes(C[vi])\n",
      "                C[vi] = A[vi] + B[vi]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "block_c = sch.get_block(\"C\")\n",
    "(i,) = sch.get_loops(block_c)\n",
    "i_0, i_1, i_2 = sch.split(i, factors=[None, 4, 4])\n",
    "print(sch.mod.script())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以对这些循环重新排序。现在我们将 i_2 移动到 i_1 的外侧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @tir.prim_func\n",
      "    def func(A: tir.Buffer[128, \"float32\"], B: tir.Buffer[128, \"float32\"], C: tir.Buffer[128, \"float32\"]) -> None:\n",
      "        # function attr dict\n",
      "        tir.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        # body\n",
      "        # with tir.block(\"root\")\n",
      "        for i_0, i_2, i_1 in tir.grid(8, 4, 4):\n",
      "            with tir.block(\"C\"):\n",
      "                vi = tir.axis.spatial(128, i_0 * 16 + i_1 * 4 + i_2)\n",
      "                tir.reads(A[vi], B[vi])\n",
      "                tir.writes(C[vi])\n",
      "                C[vi] = A[vi] + B[vi]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "sch.reorder(i_0, i_2, i_1)\n",
    "print(sch.mod.script())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们可以标注我们想要并行最外层的循环。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @tir.prim_func\n",
      "    def func(A: tir.Buffer[128, \"float32\"], B: tir.Buffer[128, \"float32\"], C: tir.Buffer[128, \"float32\"]) -> None:\n",
      "        # function attr dict\n",
      "        tir.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        # body\n",
      "        # with tir.block(\"root\")\n",
      "        for i_0 in tir.parallel(8):\n",
      "            for i_2, i_1 in tir.grid(4, 4):\n",
      "                with tir.block(\"C\"):\n",
      "                    vi = tir.axis.spatial(128, i_0 * 16 + i_1 * 4 + i_2)\n",
      "                    tir.reads(A[vi], B[vi])\n",
      "                    tir.writes(C[vi])\n",
      "                    C[vi] = A[vi] + B[vi]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "sch.parallel(i_0)\n",
    "print(sch.mod.script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.\n",
      "  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.\n",
      "  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.\n",
      "  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.\n",
      "  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.  84.\n",
      "  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.  98.\n",
      "  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111. 112.\n",
      " 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125. 126.\n",
      " 127. 128.]\n"
     ]
    }
   ],
   "source": [
    "transformed_mod = tvm.build(sch.mod, target=\"llvm\")  # The module for CPU backends.\n",
    "transformed_mod[\"main\"](a, b, c)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 通过张量表达式（Tensor Expression，TE）构造张量程序\n",
    " 在之前的例子中，我们直接使用 TVMScript 构造张量程序。在实际中，通过现有的定义方便地构造这些函数是很有帮助的。张量表达式（tensor expression）是一个帮助我们将一些可以通过表达式表示的张量计算转化为张量程序的 API。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @tir.prim_func\n",
      "    def func(A: tir.Buffer[128, \"float32\"], B: tir.Buffer[128, \"float32\"], C: tir.Buffer[128, \"float32\"]) -> None:\n",
      "        # function attr dict\n",
      "        tir.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        # body\n",
      "        # with tir.block(\"root\")\n",
      "        for i0 in tir.serial(128):\n",
      "            with tir.block(\"C\"):\n",
      "                i = tir.axis.spatial(128, i0)\n",
      "                tir.reads(A[i], B[i])\n",
      "                tir.writes(C[i])\n",
      "                C[i] = A[i] + B[i]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from tvm import te\n",
    "\n",
    "# declare the c omputation using the expression API\n",
    "A = te.placeholder((128,), name=\"A\")\n",
    "B = te.placeholder((128,), name=\"B\")\n",
    "C = te.compute((128,), lambda i: A[i] + B[i], name=\"C\")\n",
    "\n",
    "# create a function with the specified list of arguments.\n",
    "func = te.create_prim_func([A, B, C])\n",
    "func = func.with_attr(\"global_symbol\", \"main\")\n",
    "ir_mod_from_te = IRModule({\"main\": func})\n",
    "print(ir_mod_from_te.script())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 变换一个矩阵乘法程序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面的例子中，我们展示了如何变换一个向量加法程序。现在我们尝试应用一些变换到一个稍微更复杂的的程序——矩阵乘法程序。我们首先使用张量表达式 API 构造初始的张量程序，并编译执行它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.tir.function.PrimFunc'>\n",
      "primfn(var_A: handle, var_B: handle, var_C: handle) -> ()\n",
      "  attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_1: Pointer(global float32), float32, [1024, 1024], []),\n",
      "             B: Buffer(B_1: Pointer(global float32), float32, [1024, 1024], []),\n",
      "             C: Buffer(C_1: Pointer(global float32), float32, [1024, 1024], [])}\n",
      "  buffer_map = {var_A: A, var_B: B, var_C: C} {\n",
      "  block([], \"root\") {\n",
      "    tir.reads([])\n",
      "    tir.writes([])\n",
      "    for (i0: int32, 0, 1024) {\n",
      "      for (i1: int32, 0, 1024) {\n",
      "        for (i2: int32, 0, 1024) {\n",
      "          block([1024, 1024, tir.reduce_axis(0, 1024)], \"C\") as [m, n, k] {\n",
      "            bind(m, i0)\n",
      "            bind(n, i1)\n",
      "            bind(k, i2)\n",
      "            tir.reads([A[m, k], B[k, n]])\n",
      "            tir.writes([C[m, n]])\n",
      "            with init() {\n",
      "              C[m, n] = 0f32\n",
      "            }\n",
      "            C[m, n] = (C[m, n] + (A[m, k]*B[k, n]))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "}\n",
      "\n",
      "<class 'tvm.ir.module.IRModule'>\n",
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @tir.prim_func\n",
      "    def func(A: tir.Buffer[(1024, 1024), \"float32\"], B: tir.Buffer[(1024, 1024), \"float32\"], C: tir.Buffer[(1024, 1024), \"float32\"]) -> None:\n",
      "        # function attr dict\n",
      "        tir.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        # body\n",
      "        # with tir.block(\"root\")\n",
      "        for i0, i1, i2 in tir.grid(1024, 1024, 1024):\n",
      "            with tir.block(\"C\"):\n",
      "                m, n, k = tir.axis.remap(\"SSR\", [i0, i1, i2])\n",
      "                tir.reads(A[m, k], B[k, n])\n",
      "                tir.writes(C[m, n])\n",
      "                with tir.init():\n",
      "                    C[m, n] = tir.float32(0)\n",
      "                C[m, n] = C[m, n] + A[m, k] * B[k, n]\n",
      "    \n",
      "Baseline: 2.405587\n"
     ]
    }
   ],
   "source": [
    "from tvm import te\n",
    "\n",
    "M = 1024\n",
    "N = 1024\n",
    "K = 1024\n",
    "\n",
    "dtype = \"float32\"\n",
    "target = \"llvm\"\n",
    "dev = tvm.device(target, 0)\n",
    "number = 1\n",
    "\n",
    "k = te.reduce_axis((0, K), name=\"k\")\n",
    "A = te.placeholder((M, K), name=\"A\")\n",
    "B = te.placeholder((K, N), name=\"B\")\n",
    "C = te.compute((M, N), lambda m, n: te.sum(A[m, k] * B[k, n], axis=k), name=\"C\")\n",
    "\n",
    "# Default\n",
    "func = te.create_prim_func([A, B, C])\n",
    "func = func.with_attr(\"global_symbol\", \"main\")\n",
    "ir_module = tvm.IRModule({\"main\": func})\n",
    "print(type(func))\n",
    "print(func)\n",
    "print(type(ir_module))\n",
    "print(ir_module.script())\n",
    "\n",
    "# ------- 编译 -------\n",
    "\n",
    "func = tvm.build(ir_module, target=target)\n",
    "\n",
    "# ------- 执行 -------\n",
    "\n",
    "a = tvm.nd.array(np.random.randn(M, K).astype(dtype), dev)\n",
    "b = tvm.nd.array(np.random.randn(K, N).astype(dtype), dev)\n",
    "c = tvm.nd.array(np.empty((M, K), dtype=dtype), dev)\n",
    "\n",
    "func(a, b, c)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=number)\n",
    "print(\"Baseline: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tir.Schedule(0x560442358bf8)\n",
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @tir.prim_func\n",
      "    def func(A: tir.Buffer[(1024, 1024), \"float32\"], B: tir.Buffer[(1024, 1024), \"float32\"], C: tir.Buffer[(1024, 1024), \"float32\"]) -> None:\n",
      "        # function attr dict\n",
      "        tir.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        # body\n",
      "        # with tir.block(\"root\")\n",
      "        for i0_0, i1_0, i2, i0_1, i1_1 in tir.grid(32, 32, 1024, 32, 32):\n",
      "            with tir.block(\"C\"):\n",
      "                m = tir.axis.spatial(1024, i0_0 * 32 + i0_1)\n",
      "                n = tir.axis.spatial(1024, i1_0 * 32 + i1_1)\n",
      "                k = tir.axis.reduce(1024, i2)\n",
      "                tir.reads(A[m, k], B[k, n])\n",
      "                tir.writes(C[m, n])\n",
      "                with tir.init():\n",
      "                    C[m, n] = tir.float32(0)\n",
      "                C[m, n] = C[m, n] + A[m, k] * B[k, n]\n",
      "    \n",
      "{llvm -keys=cpu -link-params=0: #[version = \"0.0.5\"]\n",
      "@main = primfn(var_A: handle, var_B: handle, var_C: handle) -> ()\n",
      "  attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_1: Pointer(global float32), float32, [1048576], []),\n",
      "             B: Buffer(B_1: Pointer(global float32), float32, [1048576], []),\n",
      "             C: Buffer(C_1: Pointer(global float32), float32, [1048576], [])}\n",
      "  buffer_map = {var_A: A, var_B: B, var_C: C}\n",
      "  preflattened_buffer_map = {var_A: A_2: Buffer(A_1, float32, [1024, 1024], []), var_B: B_2: Buffer(B_1, float32, [1024, 1024], []), var_C: C_2: Buffer(C_1, float32, [1024, 1024], [])} {\n",
      "  for (i0_0: int32, 0, 32) {\n",
      "    for (i1_0: int32, 0, 32) {\n",
      "      for (i2: int32, 0, 1024) {\n",
      "        for (i0_1: int32, 0, 32) {\n",
      "          for (i1_1: int32, 0, 32) {\n",
      "            let cse_var_3: int32 = (i1_0*32)\n",
      "            let cse_var_2: int32 = ((i0_0*32768) + (i0_1*1024))\n",
      "            let cse_var_1: int32 = ((cse_var_2 + cse_var_3) + i1_1)\n",
      "             {\n",
      "              if (i2 == 0) {\n",
      "                C[cse_var_1] = 0f32\n",
      "              }\n",
      "              C[cse_var_1] = (C[cse_var_1] + (A[(cse_var_2 + i2)]*B[(((i2*1024) + cse_var_3) + i1_1)]))\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "#[metadata]\n",
      "{\n",
      "  \"root\": 1, \n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"type_key\": \"\"\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"Map\", \n",
      "      \"keys\": [\n",
      "        \"IntImm\"\n",
      "      ], \n",
      "      \"data\": [2]\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"Array\", \n",
      "      \"data\": [3]\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"bool\", \n",
      "        \"span\": \"0\", \n",
      "        \"value\": \"1\"\n",
      "      }\n",
      "    }\n",
      "  ], \n",
      "  \"b64ndarrays\": [], \n",
      "  \"attrs\": {\"tvm_version\": \"0.9.dev0\"}\n",
      "}}\n",
      "Baseline: 0.258848\n"
     ]
    }
   ],
   "source": [
    "sch = tvm.tir.Schedule(ir_module)\n",
    "print(sch)\n",
    "block_c = sch.get_block(\"C\")\n",
    "(y, x, k) = sch.get_loops(block_c)\n",
    "block_size = 64\n",
    "yo, yi = sch.split(y, [None, block_size])\n",
    "xo, xi = sch.split(x, [None, block_size])\n",
    "sch.reorder(yo, xo, k, yi, xi)\n",
    "print(sch.mod.script())\n",
    "\n",
    "# ------- 编译 -------\n",
    "func = tvm.build(sch.mod, target=target)\n",
    "print(func.ir_module_by_target)\n",
    "c = tvm.nd.array(np.empty((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=number)\n",
    "print(\"Baseline: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5cc334afce0b89effac1c4034e2a2d057ab73bae343e6f18f6adb4c89091e1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

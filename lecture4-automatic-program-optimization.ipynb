{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lecture 5 Automatic program optimization\n",
    "在之前的课程中我们了解了如何去构建一个 primitive tensor function 并且将其整合成端到端的模型，下面为涉及到的三个抽象：\n",
    "- A computational graph view that drives the high-level executions.\n",
    "- Abstraction for primitive tensor functions.\n",
    "- Library function calls via environment function registration.\n",
    "\n",
    "有很多不同的方式来变换相同的程序，这一章将会讨论自动化这一过程，能够较为快速地找到最优的变换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备\n",
    "import some package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import tvm\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm.script import tir as T, relax as R\n",
    "import numpy as np\n",
    "from tvm import relax\n",
    "# This is needed for deferring annotation parsing in TVMScript\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: Transform a Primitive Tensor Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix multiply\n",
    "@tvm.script.ir_module\n",
    "class MyModule:\n",
    "    @T.prim_func\n",
    "    def main(\n",
    "        A: T.Buffer[(128, 128), \"float32\"],\n",
    "        B: T.Buffer[(128, 128), \"float32\"],\n",
    "        C: T.Buffer[(128, 128), \"float32\"]\n",
    "    ):\n",
    "        T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
    "        for i, j, k in T.grid(128, 128, 128):\n",
    "            with T.block(\"C\"):\n",
    "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
    "                with T.init():\n",
    "                    C[vi, vj] = T.float32(0.0)\n",
    "                C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vk, vj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = \"float32\"\n",
    "a_np = np.random.rand(128, 128).astype(dtype)\n",
    "b_np = np.random.rand(128, 128).astype(dtype)\n",
    "c_mm = a_np @ b_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost of MyModule: 2.843 ms\n"
     ]
    }
   ],
   "source": [
    "a_nd = tvm.nd.array(a_np)\n",
    "b_nd = tvm.nd.array(b_np)\n",
    "c_nd = tvm.nd.array(np.empty((128, 128), dtype=\"float32\"))\n",
    "\n",
    "lib = tvm.build(MyModule, target=\"llvm\")\n",
    "f_timer_before = lib.time_evaluator(\"main\", tvm.cpu())\n",
    "print(\"Time cost of MyModule: %.3f ms\" % (f_timer_before(a_nd, b_nd, c_nd).mean * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform MyModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule_mm(sch: tvm.tir.Schedule, jfactor=4):\n",
    "    block_C = sch.get_block(\"C\", \"main\")\n",
    "    i, j, k = sch.get_loops(block=block_C)\n",
    "    j_0, j_1 = sch.split(loop=j, factors=[None, jfactor])\n",
    "    sch.reorder(i, j_0, k, j_1)\n",
    "    sch.decompose_reduction(block_C, k)\n",
    "    return sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @tir.prim_func\n",
      "    def main(A: tir.Buffer[(128, 128), \"float32\"], B: tir.Buffer[(128, 128), \"float32\"], C: tir.Buffer[(128, 128), \"float32\"]) -> None:\n",
      "        # function attr dict\n",
      "        tir.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        # body\n",
      "        # with tir.block(\"root\")\n",
      "        for i, j_0 in tir.grid(128, 32):\n",
      "            for j_1_init in tir.serial(4):\n",
      "                with tir.block(\"C_init\"):\n",
      "                    vi = tir.axis.spatial(128, i)\n",
      "                    vj = tir.axis.spatial(128, j_0 * 4 + j_1_init)\n",
      "                    tir.reads()\n",
      "                    tir.writes(C[vi, vj])\n",
      "                    C[vi, vj] = tir.float32(0)\n",
      "            for k, j_1 in tir.grid(128, 4):\n",
      "                with tir.block(\"C_update\"):\n",
      "                    vi = tir.axis.spatial(128, i)\n",
      "                    vj = tir.axis.spatial(128, j_0 * 4 + j_1)\n",
      "                    vk = tir.axis.reduce(128, k)\n",
      "                    tir.reads(C[vi, vj], A[vi, vk], B[vk, vj])\n",
      "                    tir.writes(C[vi, vj])\n",
      "                    C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vk, vj]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "sch = tvm.tir.Schedule(MyModule)\n",
    "sch = schedule_mm(sch)\n",
    "print(sch.mod.script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost of MyModule=>schedule_mm: 1.979 ms\n"
     ]
    }
   ],
   "source": [
    "lib = tvm.build(sch.mod, target=\"llvm\")\n",
    "f_timer_after = lib.time_evaluator(\"main\", tvm.cpu())\n",
    "print(\"Time cost of MyModule=>schedule_mm: %.3f ms\" % (f_timer_after(a_nd, b_nd, c_nd).mean * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0 = sch.get_block(name=\"C\", func_name=\"main\")\n",
      "l1, l2, l3 = sch.get_loops(block=b0)\n",
      "l4, l5 = sch.split(loop=l2, factors=[None, 4])\n",
      "sch.reorder(l1, l4, l3, l5)\n",
      "b6 = sch.decompose_reduction(block=b0, loop=l3)\n"
     ]
    }
   ],
   "source": [
    "print(sch.trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 和我们刚才写的 schedule 相同\n",
    "def schedule_mm(sch: tvm.tir.Schedule, jfactor=4):\n",
    "    block_C = sch.get_block(\"C\", \"main\")\n",
    "    i, j, k = sch.get_loops(block=block_C)\n",
    "    j_0, j_1 = sch.split(loop=j, factors=[None, jfactor])\n",
    "    sch.reorder(i, j_0, k, j_1)\n",
    "    sch.decompose_reduction(block_C, k)\n",
    "    return sch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic schedule transformation\n",
    "到目前为止，我们已经知道了我们能够根据自己的先验知识设置变换参数对张量程序进行变换，但是在实际应用中，我们不可能手动穷举所有的变换可能，\n",
    "\n",
    "一个比较实际的想法是在这些可能的变换中设置一些变量\n",
    "\n",
    "下面的代码通过 `sch.sample_perfect_tile` 来得到随机变量 `jfactor`，每次执行后的 `jfactor` 的值都不相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0 = sch.get_block(name=\"C\", func_name=\"main\")\n",
      "l1, l2, l3 = sch.get_loops(block=b0)\n",
      "v4, v5 = sch.sample_perfect_tile(loop=l2, n=2, max_innermost_factor=16, decision=[128, 1])\n",
      "l6, l7 = sch.split(loop=l2, factors=[v4, v5])\n",
      "sch.reorder(l1, l6, l3, l7)\n",
      "b8 = sch.decompose_reduction(block=b0, loop=l3)\n"
     ]
    }
   ],
   "source": [
    "def stochastic_schedule_mm(sch: tvm.tir.Schedule):\n",
    "    block_C = sch.get_block(\"C\", \"main\")\n",
    "    i, j, k = sch.get_loops(block=block_C)\n",
    "    jfactors = sch.sample_perfect_tile(loop=j, n = 2)\n",
    "    j_0, j_1 = sch.split(loop=j, factors=jfactors)\n",
    "    sch.reorder(i, j_0, k, j_1)\n",
    "    sch.decompose_reduction(block_C, k)\n",
    "    return sch\n",
    "sch = tvm.tir.Schedule(MyModule)\n",
    "print(stochastic_schedule_mm(sch).trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将 `jfactor` 设置为变量之后我们就得到了一个程序空间，我们可以通过在这个程序空间中进行搜索得到最优化的程序\n",
    "\n",
    "Elements in the j_factors are not real integer numbers. Instead, they are symbolic variables that refer to a random variable being sampled. We can pass these variables to the transformation API to specify choices such as factor values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.tir.expr.Var"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch = tvm.tir.Schedule(MyModule)\n",
    "block_C = sch.get_block(\"C\", \"main\")\n",
    "i, j, k = sch.get_loops(block=block_C)\n",
    "j_factors = sch.sample_perfect_tile(loop=j, n=2)\n",
    "type(j_factors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0 = sch.get_block(name=\"C\", func_name=\"main\")\n",
      "l1, l2, l3 = sch.get_loops(block=b0)\n",
      "v4, v5 = sch.sample_perfect_tile(loop=l2, n=2, max_innermost_factor=16, decision=[128, 1])\n"
     ]
    }
   ],
   "source": [
    "print(sch.trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search over stochastic transformation\n",
    "我们已经使用 `stochastic_schedule_mm` 将一个初始的程序变为了一个在功能上等价的，但是有不同的实现的程序空间\n",
    "\n",
    "那么如何从这个程序空间中得到最好的程序呢？\n",
    "\n",
    "我们需要一个搜索算法，下面是一种比较直接的搜索算法——随机搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Attempt 0, time-cost: 2.007 ms====\n",
      "b0 = sch.get_block(name=\"C\", func_name=\"main\")\n",
      "l1, l2, l3 = sch.get_loops(block=b0)\n",
      "v4, v5 = sch.sample_perfect_tile(loop=l2, n=2, max_innermost_factor=16, decision=[32, 4])\n",
      "l6, l7 = sch.split(loop=l2, factors=[v4, v5])\n",
      "sch.reorder(l1, l6, l3, l7)\n",
      "b8 = sch.decompose_reduction(block=b0, loop=l3)\n",
      "=====Attempt 1, time-cost: 1.522 ms====\n",
      "b0 = sch.get_block(name=\"C\", func_name=\"main\")\n",
      "l1, l2, l3 = sch.get_loops(block=b0)\n",
      "v4, v5 = sch.sample_perfect_tile(loop=l2, n=2, max_innermost_factor=16, decision=[8, 16])\n",
      "l6, l7 = sch.split(loop=l2, factors=[v4, v5])\n",
      "sch.reorder(l1, l6, l3, l7)\n",
      "b8 = sch.decompose_reduction(block=b0, loop=l3)\n",
      "=====Attempt 2, time-cost: 1.242 ms====\n",
      "b0 = sch.get_block(name=\"C\", func_name=\"main\")\n",
      "l1, l2, l3 = sch.get_loops(block=b0)\n",
      "v4, v5 = sch.sample_perfect_tile(loop=l2, n=2, max_innermost_factor=16, decision=[16, 8])\n",
      "l6, l7 = sch.split(loop=l2, factors=[v4, v5])\n",
      "sch.reorder(l1, l6, l3, l7)\n",
      "b8 = sch.decompose_reduction(block=b0, loop=l3)\n",
      "=====Attempt 3, time-cost: 1.858 ms====\n",
      "b0 = sch.get_block(name=\"C\", func_name=\"main\")\n",
      "l1, l2, l3 = sch.get_loops(block=b0)\n",
      "v4, v5 = sch.sample_perfect_tile(loop=l2, n=2, max_innermost_factor=16, decision=[128, 1])\n",
      "l6, l7 = sch.split(loop=l2, factors=[v4, v5])\n",
      "sch.reorder(l1, l6, l3, l7)\n",
      "b8 = sch.decompose_reduction(block=b0, loop=l3)\n",
      "=====Attempt 4, time-cost: 1.293 ms====\n",
      "b0 = sch.get_block(name=\"C\", func_name=\"main\")\n",
      "l1, l2, l3 = sch.get_loops(block=b0)\n",
      "v4, v5 = sch.sample_perfect_tile(loop=l2, n=2, max_innermost_factor=16, decision=[16, 8])\n",
      "l6, l7 = sch.split(loop=l2, factors=[v4, v5])\n",
      "sch.reorder(l1, l6, l3, l7)\n",
      "b8 = sch.decompose_reduction(block=b0, loop=l3)\n"
     ]
    }
   ],
   "source": [
    "def random_search(mod: tvm.ir.IRModule, num_trials: int = 5):\n",
    "    \n",
    "    best_result = None\n",
    "    best_sch = None\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        sch = stochastic_schedule_mm(tvm.tir.Schedule(mod))\n",
    "        lib = tvm.build(sch.mod, target=\"llvm\")\n",
    "        f_timer_after = lib.time_evaluator(\"main\", tvm.cpu())\n",
    "        result = f_timer_after(a_nd, b_nd, c_nd).mean\n",
    "\n",
    "        print(\"=====Attempt %d, time-cost: %.3f ms====\" % (i, result * 1000))\n",
    "        print(sch.trace)\n",
    "        if best_result is None or result < best_result:\n",
    "            best_result = result\n",
    "            best_sch = sch      \n",
    "    return best_sch\n",
    "\n",
    "sch = random_search(MyModule, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0 = sch.get_block(name=\"C\", func_name=\"main\")\n",
      "l1, l2, l3 = sch.get_loops(block=b0)\n",
      "v4, v5 = sch.sample_perfect_tile(loop=l2, n=2, max_innermost_factor=16, decision=[16, 8])\n",
      "l6, l7 = sch.split(loop=l2, factors=[v4, v5])\n",
      "sch.reorder(l1, l6, l3, l7)\n",
      "b8 = sch.decompose_reduction(block=b0, loop=l3)\n"
     ]
    }
   ],
   "source": [
    "print(sch.trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在实际中我们使用更加智能的算法帮助我们找到最优程序，我们可以使用 `tvm` 提供的 `meta_schedule`\n",
    "\n",
    "key idea: use stochastic transformation to specify a search space of good programs, tune_tir API helps to search and find an optimized solution within the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 14:20:17.701 INFO Logging directory: ./tune_tmp/logs\n",
      "2022-07-20 14:20:17.705 INFO Logging directory: ./tune_tmp/logs\n",
      "2022-07-20 14:20:17.706 INFO Working directory: ./tune_tmp\n",
      "2022-07-20 14:20:17.707 INFO Creating JSONDatabase. Workload at: ./tune_tmp/database_workload.json. Tuning records at: ./tune_tmp/database_tuning_record.json\n",
      "2022-07-20 14:20:17.724 INFO LocalBuilder: max_workers = 48\n",
      "2022-07-20 14:20:18.480 INFO LocalRunner: max_workers = 1\n",
      "2022-07-20 14:20:19.206 INFO Initializing Task #0: \"main\"\n",
      "2022-07-20 14:20:19.368 INFO \n",
      " ID | Name |    FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 4194304 |      1 |            N/A |          N/A |                   N/A |      0 |            \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 0\n",
      "Total latency (us): 0\n",
      "\n",
      "2022-07-20 14:20:19.370 INFO Scheduler picks Task #0: \"main\"\n",
      "2022-07-20 14:20:21.621 INFO Sending 5 sample(s) to builder\n",
      "2022-07-20 14:20:22.834 INFO Sending 5 sample(s) to runner\n",
      "2022-07-20 14:20:24.480 INFO [Updated] Task #0: \"main\"\n",
      " ID | Name |    FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 4194304 |      1 |         3.2441 |    1292.9053 |             1292.9053 |      5 |            \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 5\n",
      "Total latency (us): 1292.91\n",
      "\n",
      "2022-07-20 14:20:24.482 INFO Scheduler picks Task #0: \"main\"\n",
      "2022-07-20 14:20:26.638 INFO Sending 0 sample(s) to builder\n",
      "2022-07-20 14:20:26.640 INFO Sending 0 sample(s) to runner\n",
      "2022-07-20 14:20:26.641 INFO [Updated] Task #0: \"main\"\n",
      " ID | Name |    FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 4194304 |      1 |         3.2441 |    1292.9053 |             1292.9053 |      5 |            \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 5\n",
      "Total latency (us): 1292.91\n",
      "\n",
      "2022-07-20 14:20:26.642 INFO Scheduler picks Task #0: \"main\"\n",
      "2022-07-20 14:20:28.794 INFO Sending 0 sample(s) to builder\n",
      "2022-07-20 14:20:28.797 INFO Sending 0 sample(s) to runner\n",
      "2022-07-20 14:20:28.799 INFO [Updated] Task #0: \"main\"\n",
      " ID | Name |    FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 4194304 |      1 |         3.2441 |    1292.9053 |             1292.9053 |      5 |            \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 5\n",
      "Total latency (us): 1292.91\n",
      "\n",
      "2022-07-20 14:20:28.800 INFO Scheduler picks Task #0: \"main\"\n",
      "2022-07-20 14:20:30.934 INFO Sending 0 sample(s) to builder\n",
      "2022-07-20 14:20:30.938 INFO Sending 0 sample(s) to runner\n",
      "2022-07-20 14:20:30.940 INFO [Updated] Task #0: \"main\"\n",
      " ID | Name |    FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 4194304 |      1 |         3.2441 |    1292.9053 |             1292.9053 |      5 |            \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 5\n",
      "Total latency (us): 1292.91\n",
      "\n",
      "2022-07-20 14:20:30.941 INFO Scheduler picks Task #0: \"main\"\n",
      "2022-07-20 14:20:33.134 INFO Sending 0 sample(s) to builder\n",
      "2022-07-20 14:20:33.138 INFO Sending 0 sample(s) to runner\n",
      "2022-07-20 14:20:33.140 INFO [Updated] Task #0: \"main\"\n",
      " ID | Name |    FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 4194304 |      1 |         3.2441 |    1292.9053 |             1292.9053 |      5 |            \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 5\n",
      "Total latency (us): 1292.91\n",
      "\n",
      "2022-07-20 14:20:33.141 INFO Scheduler picks Task #0: \"main\"\n",
      "2022-07-20 14:20:35.271 INFO Task #0 has finished. Remaining task(s): 0\n",
      "2022-07-20 14:20:35.307 INFO Saved XGBModel to ./tune_tmp/cost_model.xgb\n"
     ]
    }
   ],
   "source": [
    "import shutil \n",
    "\n",
    "from tvm import meta_schedule as ms\n",
    "# 记得每次重新运行将文件夹 \"./tune_tmp\" 删除 \n",
    "work_dir = \"./tune_tmp\"\n",
    "sch_tuned = ms.tune_tir(\n",
    "    mod = MyModule,\n",
    "    target = \"llvm --num-cores=1\",\n",
    "    config=ms.TuneConfig(\n",
    "      max_trials_global=64,\n",
    "      num_trials_per_iter=64,\n",
    "    ),\n",
    "    space=ms.space_generator.ScheduleFn(stochastic_schedule_mm),\n",
    "    work_dir=work_dir,\n",
    "    task_name=\"main\"\n",
    ")\n",
    "\n",
    "shutil.rmtree(work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看搜索后的变换的 `trace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0 = sch.get_block(name=\"C\", func_name=\"main\")\n",
      "l1, l2, l3 = sch.get_loops(block=b0)\n",
      "v4, v5 = sch.sample_perfect_tile(loop=l2, n=2, max_innermost_factor=16, decision=[8, 16])\n",
      "l6, l7 = sch.split(loop=l2, factors=[v4, v5])\n",
      "sch.reorder(l1, l6, l3, l7)\n",
      "b8 = sch.decompose_reduction(block=b0, loop=l3)\n",
      "sch.enter_postproc()\n"
     ]
    }
   ],
   "source": [
    "print(sch_tuned.trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看经过搜索后的程序表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost of MyModule after tuning: 1.530 ms\n"
     ]
    }
   ],
   "source": [
    "lib = tvm.build(sch_tuned.mod, target=\"llvm\")\n",
    "time_eval = lib.time_evaluator(\"main\", tvm.cpu())\n",
    "print(\"Time cost of MyModule after tuning: %.3f ms\" % (time_eval(a_nd, b_nd, c_nd).mean * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leverage Default AutoScheduling\n",
    "之前是我们指定了一个变换变量，形成的程序空间，实际上我们可以直接通过 `AutoScheduling` 来对程序进行可能的张量变换的搜索，在 `AutoScheduling` 中会自动寻找那些地方可能会需要搜索从而实现更好的优化，当然我们也可以结合人的先验知识，像上面这个例子一样通过 `space=ms.space_generator.ScheduleFn(stochastic_schedule_mm),` 自己指定一个搜索空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 14:21:39.099 INFO Logging directory: ./tune_tmp/logs\n",
      "2022-07-20 14:21:39.103 INFO Logging directory: ./tune_tmp/logs\n",
      "2022-07-20 14:21:39.104 INFO Working directory: ./tune_tmp\n",
      "2022-07-20 14:21:39.105 INFO Creating JSONDatabase. Workload at: ./tune_tmp/database_workload.json. Tuning records at: ./tune_tmp/database_tuning_record.json\n",
      "2022-07-20 14:21:39.148 INFO LocalBuilder: max_workers = 48\n",
      "2022-07-20 14:21:39.833 INFO LocalRunner: max_workers = 1\n",
      "2022-07-20 14:21:40.483 INFO Initializing Task #0: \"main\"\n",
      "2022-07-20 14:21:40.643 INFO \n",
      " ID | Name |    FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 4194304 |      1 |            N/A |          N/A |                   N/A |      0 |            \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 0\n",
      "Total latency (us): 0\n",
      "\n",
      "2022-07-20 14:21:40.644 INFO Scheduler picks Task #0: \"main\"\n",
      "2022-07-20 14:21:45.323 INFO Sending 64 sample(s) to builder\n",
      "2022-07-20 14:22:06.607 INFO Sending 64 sample(s) to runner\n",
      "2022-07-20 14:22:21.684 INFO [Updated] Task #0: \"main\"\n",
      " ID | Name |    FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 4194304 |      1 |       247.2008 |      16.9672 |               16.9672 |     64 |            \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 64\n",
      "Total latency (us): 16.9672\n",
      "\n",
      "2022-07-20 14:22:21.686 INFO Task #0 has finished. Remaining task(s): 0\n",
      "2022-07-20 14:22:21.756 INFO Saved XGBModel to ./tune_tmp/cost_model.xgb\n"
     ]
    }
   ],
   "source": [
    "sch_tuned = ms.tune_tir(\n",
    "    mod=MyModule,\n",
    "    target=\"llvm --num-cores=1\",\n",
    "    config=ms.TuneConfig(\n",
    "      max_trials_global=64,\n",
    "      num_trials_per_iter=64,\n",
    "    ),\n",
    "    work_dir=work_dir,\n",
    "    task_name=\"main\",\n",
    ")\n",
    "shutil.rmtree(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost of MyModule after tuning: 0.066 ms\n"
     ]
    }
   ],
   "source": [
    "lib = tvm.build(sch_tuned.mod, target=\"llvm\")\n",
    "time_eval = lib.time_evaluator(\"main\", tvm.cpu())\n",
    "print(\"Time cost of MyModule after tuning: %.3f ms\" % (time_eval(a_nd, b_nd, c_nd).mean * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b0 = sch.get_block(name=\"C\", func_name=\"main\")\n",
       "b1 = sch.get_block(name=\"root\", func_name=\"main\")\n",
       "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")\n",
       "l2, l3, l4 = sch.get_loops(block=b0)\n",
       "v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[4, 4, 1, 8])\n",
       "l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])\n",
       "v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 8, 1, 16])\n",
       "l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])\n",
       "v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[64, 2])\n",
       "l23, l24 = sch.split(loop=l4, factors=[v21, v22])\n",
       "sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)\n",
       "b25 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope=\"global\")\n",
       "sch.reverse_compute_at(block=b25, loop=l18, preserve_unit_loops=True)\n",
       "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.parallel\", ann_val=16)\n",
       "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.vectorize\", ann_val=64)\n",
       "v26 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)\n",
       "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v26)\n",
       "sch.enter_postproc()\n",
       "b27 = sch.get_block(name=\"root\", func_name=\"main\")\n",
       "sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.parallel\")\n",
       "sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.vectorize\")\n",
       "sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.unroll_explicit\")\n",
       "b28, b29 = sch.get_child_blocks(b27)\n",
       "l30, l31, l32, l33, l34, l35, l36, l37, l38, l39 = sch.get_loops(block=b28)\n",
       "l40 = sch.fuse(l30, l31, l32, l33)\n",
       "sch.parallel(loop=l40)\n",
       "l41 = sch.fuse(l39)\n",
       "sch.vectorize(loop=l41)\n",
       "sch.annotate(block_or_loop=l40, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)\n",
       "sch.annotate(block_or_loop=l40, ann_key=\"pragma_unroll_explicit\", ann_val=1)\n",
       "l42, l43, l44 = sch.get_loops(block=b29)\n",
       "l45 = sch.fuse(l44)\n",
       "sch.vectorize(loop=l45)\n",
       "sch.annotate(block_or_loop=l42, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)\n",
       "sch.annotate(block_or_loop=l42, ann_key=\"pragma_unroll_explicit\", ann_val=1)\n",
       "b46 = sch.get_block(name=\"C\", func_name=\"main\")\n",
       "l47, l48, l49, l50, l51, l52, l53 = sch.get_loops(block=b46)\n",
       "b54 = sch.decompose_reduction(block=b46, loop=l48)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch_tuned.trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @tir.prim_func\n",
      "    def main(A: tir.Buffer[(128, 128), \"float32\"], B: tir.Buffer[(128, 128), \"float32\"], C: tir.Buffer[(128, 128), \"float32\"]) -> None:\n",
      "        # function attr dict\n",
      "        tir.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        # body\n",
      "        # with tir.block(\"root\")\n",
      "        C_global = tir.alloc_buffer([128, 128], dtype=\"float32\")\n",
      "        for i_0_j_0_i_1_j_1_fused in tir.parallel(128, annotations={\"pragma_auto_unroll_max_step\":16, \"pragma_unroll_explicit\":1}):\n",
      "            for i_2_init, j_2_init, i_3_init in tir.grid(1, 1, 8):\n",
      "                for j_3_fused_init in tir.vectorized(16):\n",
      "                    with tir.block(\"C_init\"):\n",
      "                        vi = tir.axis.spatial(128, (i_0_j_0_i_1_j_1_fused // 32 * 4 + i_0_j_0_i_1_j_1_fused % 32 // 8 + i_2_init) * 8 + i_3_init)\n",
      "                        vj = tir.axis.spatial(128, (0 * 8 + i_0_j_0_i_1_j_1_fused % 8 + j_2_init) * 16 + j_3_fused_init)\n",
      "                        tir.reads()\n",
      "                        tir.writes(C_global[vi, vj])\n",
      "                        tir.block_attr({\"meta_schedule.tiling_structure\":\"SSRSRS\"})\n",
      "                        C_global[vi, vj] = tir.float32(0)\n",
      "            for k_0, i_2, j_2, k_1, i_3 in tir.grid(64, 1, 1, 2, 8):\n",
      "                for j_3_fused in tir.vectorized(16):\n",
      "                    with tir.block(\"C_update\"):\n",
      "                        vi = tir.axis.spatial(128, (i_0_j_0_i_1_j_1_fused // 32 * 4 + i_0_j_0_i_1_j_1_fused % 32 // 8 + i_2) * 8 + i_3)\n",
      "                        vj = tir.axis.spatial(128, (0 * 8 + i_0_j_0_i_1_j_1_fused % 8 + j_2) * 16 + j_3_fused)\n",
      "                        vk = tir.axis.reduce(128, k_0 * 2 + k_1)\n",
      "                        tir.reads(C_global[vi, vj], A[vi, vk], B[vk, vj])\n",
      "                        tir.writes(C_global[vi, vj])\n",
      "                        tir.block_attr({\"meta_schedule.tiling_structure\":\"SSRSRS\"})\n",
      "                        C_global[vi, vj] = C_global[vi, vj] + A[vi, vk] * B[vk, vj]\n",
      "            for ax0 in tir.serial(8):\n",
      "                for ax1_fused in tir.vectorized(16):\n",
      "                    with tir.block(\"C_global\"):\n",
      "                        v0 = tir.axis.spatial(128, i_0_j_0_i_1_j_1_fused // 32 * 32 + i_0_j_0_i_1_j_1_fused % 32 // 8 * 8 + ax0)\n",
      "                        v1 = tir.axis.spatial(128, i_0_j_0_i_1_j_1_fused % 8 * 16 + ax1_fused)\n",
      "                        tir.reads(C_global[v0, v1])\n",
      "                        tir.writes(C[v0, v1])\n",
      "                        C[v0, v1] = C_global[v0, v1]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(sch_tuned.mod.script())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们对到目前为止所学的内容进行检查。\n",
    "\n",
    "- 随机调度允许我们表示“可能的变换是什么”。\n",
    "\n",
    "- Meta-Schedule 的 tune_tir API 帮助我们在搜索空间内找到一个好的解决方案。\n",
    "\n",
    "- Meta-Schedule 带有一组默认的内置随机变换，涵盖了广泛的搜索空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回到端到端模型执行\n",
    "到目前为止，我们已经学会了自动优化单个元张量函数。我们如何才能把利用它改进我们的端到端模型执行？\n",
    "\n",
    "从 MLC 的角度来看，自动搜索是一个模块化的步骤，我们只需要用调优结果提供的新的元张量函数实现替换原始的元张量函数实现。\n",
    "\n",
    "我们将重用上一章中的两层 MLP 示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "img, label = next(iter(test_loader))\n",
    "img = img.reshape(1, 28, 28).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Coat\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "print(\"Class:\", class_names[label[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们同样下载我们将在示例中使用的预训练模型参数。（linear -> relu ->linear）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 “fasionmnist_mlp_params.pkl” 已经存在；不获取。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hide outputs\n",
    "!wget -nc https://github.com/mlc-ai/web-data/raw/main/models/fasionmnist_mlp_params.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "mlp_params = pkl.load(open(\"fasionmnist_mlp_params.pkl\", \"rb\"))\n",
    "\n",
    "data_nd = tvm.nd.array(img.reshape(1, 784))\n",
    "nd_params = {k: tvm.nd.array(v) for k, v in mlp_params.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们使用一个混合 IRModule。它其中大多数步骤都调用环境函数，同时带有一个 TensorIR 函数 linear0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyModuleMixture:\n",
    "    @T.prim_func\n",
    "    def linear0(X: T.Buffer[(1, 784), \"float32\"],\n",
    "                W: T.Buffer[(128, 784), \"float32\"],\n",
    "                B: T.Buffer[(128,), \"float32\"],\n",
    "                Z: T.Buffer[(1, 128), \"float32\"]):\n",
    "        T.func_attr({\"global_symbol\": \"linear0\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer((1, 128), \"float32\")\n",
    "        for i, j, k in T.grid(1, 128, 784):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
    "                with T.init():\n",
    "                    Y[vi, vj] = T.float32(0)\n",
    "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
    "\n",
    "        for i, j in T.grid(1, 128):\n",
    "            with T.block(\"Z\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] =  Y[vi, vj] + B[vj]\n",
    "\n",
    "    @R.function\n",
    "    def main(x: Tensor((1, 784), \"float32\"),\n",
    "             w0: Tensor((128, 784), \"float32\"),\n",
    "             b0: Tensor((128,), \"float32\"),\n",
    "             w1: Tensor((10, 128), \"float32\"),\n",
    "             b1: Tensor((10,), \"float32\")):\n",
    "        with R.dataflow():\n",
    "            lv0 = R.call_tir(linear0, (x, w0, b0), (1, 128), dtype=\"float32\")\n",
    "            lv1 = R.call_tir(\"env.relu\", (lv0,), (1, 128), dtype=\"float32\")\n",
    "            out = R.call_tir(\"env.linear\", (lv1, w1, b1), (1, 10), dtype=\"float32\")\n",
    "            R.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.register_func(\"env.linear\", override=True)\n",
    "def torch_linear(x: tvm.nd.NDArray,\n",
    "                 w: tvm.nd.NDArray,\n",
    "                 b: tvm.nd.NDArray,\n",
    "                 out: tvm.nd.NDArray):\n",
    "    x_torch = torch.from_dlpack(x)\n",
    "    w_torch = torch.from_dlpack(w)\n",
    "    b_torch = torch.from_dlpack(b)\n",
    "    out_torch = torch.from_dlpack(out)\n",
    "    torch.mm(x_torch, w_torch.T, out=out_torch)\n",
    "    torch.add(out_torch, b_torch, out=out_torch)\n",
    "\n",
    "@tvm.register_func(\"env.relu\", override=True)\n",
    "def lnumpy_relu(x: tvm.nd.NDArray,\n",
    "                out: tvm.nd.NDArray):\n",
    "    x_torch = torch.from_dlpack(x   )\n",
    "    out_torch = torch.from_dlpack(out)\n",
    "    torch.maximum(x_torch, torch.Tensor([0.0]), out=out_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以绑定参数，看看它是否给出了正确的预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModuleWithParams = relax.transform.BindParams(\"main\", nd_params)(MyModuleMixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModuleWithParams Prediction: Coat\n"
     ]
    }
   ],
   "source": [
    "ex = relax.vm.build(MyModuleWithParams, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "\n",
    "nd_res = vm[\"main\"](data_nd)\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MyModuleWithParams Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModuleWithParams time-cost: 0.284531 ms\n"
     ]
    }
   ],
   "source": [
    "ftimer = vm.module.time_evaluator(\"main\", tvm.cpu(), number=100)\n",
    "\n",
    "print(\"MyModuleWithParams time-cost: %g ms\" % (ftimer(data_nd).mean * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前，调优 API 只接受一个带有一个 main 函数的 IRModule，所以我们首先将 linear0 取出到另一个模块的 main 函数中并将其传递给 tune_tir。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @tir.prim_func\n",
      "    def main(X: tir.Buffer[(1, 784), \"float32\"], W: tir.Buffer[(128, 784), \"float32\"], B: tir.Buffer[128, \"float32\"], Z: tir.Buffer[(1, 128), \"float32\"]) -> None:\n",
      "        # function attr dict\n",
      "        tir.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        # body\n",
      "        # with tir.block(\"root\")\n",
      "        Y = tir.alloc_buffer([1, 128], dtype=\"float32\")\n",
      "        for i, j, k in tir.grid(1, 128, 784):\n",
      "            with tir.block(\"Y\"):\n",
      "                vi, vj, vk = tir.axis.remap(\"SSR\", [i, j, k])\n",
      "                tir.reads(X[vi, vk], W[vj, vk])\n",
      "                tir.writes(Y[vi, vj])\n",
      "                with tir.init():\n",
      "                    Y[vi, vj] = tir.float32(0)\n",
      "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
      "        for i, j in tir.grid(1, 128):\n",
      "            with tir.block(\"Z\"):\n",
      "                vi, vj = tir.axis.remap(\"SS\", [i, j])\n",
      "                tir.reads(Y[vi, vj], B[vj])\n",
      "                tir.writes(Z[vi, vj])\n",
      "                Z[vi, vj] = Y[vi, vj] + B[vj]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "mod_linear = tvm.IRModule.from_expr(MyModuleMixture[\"linear0\"].with_attr(\"global_symbol\", \"main\"))\n",
    "print(mod_linear.script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 14:29:20.415 INFO Logging directory: ./tune_tmp/logs\n",
      "2022-07-20 14:29:20.419 INFO Logging directory: ./tune_tmp/logs\n",
      "2022-07-20 14:29:20.420 INFO Working directory: ./tune_tmp\n",
      "2022-07-20 14:29:20.421 INFO Creating JSONDatabase. Workload at: ./tune_tmp/database_workload.json. Tuning records at: ./tune_tmp/database_tuning_record.json\n",
      "2022-07-20 14:29:20.422 INFO LocalBuilder: max_workers = 48\n",
      "2022-07-20 14:29:21.178 INFO LocalRunner: max_workers = 1\n",
      "2022-07-20 14:29:21.878 INFO Initializing Task #0: \"main\"\n",
      "2022-07-20 14:29:22.116 INFO \n",
      " ID | Name |   FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 200832 |      1 |            N/A |          N/A |                   N/A |      0 |            \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Total trials: 0\n",
      "Total latency (us): 0\n",
      "\n",
      "2022-07-20 14:29:22.118 INFO Scheduler picks Task #0: \"main\"\n",
      "2022-07-20 14:29:27.046 INFO Sending 64 sample(s) to builder\n",
      "2022-07-20 14:29:39.908 INFO Sending 64 sample(s) to runner\n",
      "2022-07-20 14:29:56.115 INFO [Updated] Task #0: \"main\"\n",
      " ID | Name |   FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 200832 |      1 |        34.2804 |       5.8585 |                5.8585 |     64 |            \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Total trials: 64\n",
      "Total latency (us): 5.8585\n",
      "\n",
      "2022-07-20 14:29:56.118 INFO Task #0 has finished. Remaining task(s): 0\n",
      "2022-07-20 14:29:56.199 INFO Saved XGBModel to ./tune_tmp/cost_model.xgb\n"
     ]
    }
   ],
   "source": [
    "sch_tuned_linear = ms.tune_tir(\n",
    "    mod=mod_linear,\n",
    "    target=\"llvm --num-cores=1\",\n",
    "    config=ms.TuneConfig(\n",
    "      max_trials_global=64,\n",
    "      num_trials_per_iter=64,\n",
    "    ),\n",
    "    work_dir=work_dir,\n",
    "    task_name=\"main\",\n",
    ")\n",
    "\n",
    "shutil.rmtree(work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用调优后的新函数替换原来的函数。我们可以通过首先获得一个 global_var（一个指向 IRModule 中函数的 pointer 引用），然后调用 update_func 来用新的函数替换原本的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @relax.function\n",
      "    def main(x: Tensor((1, 784), \"float32\")) -> Tensor(None, \"float32\", ndim = 2):\n",
      "        # block 0\n",
      "        with relax.dataflow():\n",
      "            lv0 = relax.call_tir(linear0, (x, meta[relay.Constant][0], meta[relay.Constant][1]), (1, 128), dtype=\"float32\")\n",
      "            lv1 = relax.call_tir(\"env.relu\", (lv0,), (1, 128), dtype=\"float32\")\n",
      "            out = relax.call_tir(\"env.linear\", (lv1, meta[relay.Constant][2], meta[relay.Constant][3]), (1, 10), dtype=\"float32\")\n",
      "            relax.output(out)\n",
      "        return out\n",
      "    \n",
      "    @tir.prim_func\n",
      "    def linear0(X: tir.Buffer[(1, 784), \"float32\"], W: tir.Buffer[(128, 784), \"float32\"], B: tir.Buffer[128, \"float32\"], Z: tir.Buffer[(1, 128), \"float32\"]) -> None:\n",
      "        # function attr dict\n",
      "        tir.func_attr({\"global_symbol\": \"linear0\", \"tir.noalias\": True})\n",
      "        # body\n",
      "        # with tir.block(\"root\")\n",
      "        Y = tir.alloc_buffer([1, 128], dtype=\"float32\")\n",
      "        for i_0_j_0_i_1_j_1_fused in tir.parallel(16, annotations={\"pragma_auto_unroll_max_step\":64, \"pragma_unroll_explicit\":1}):\n",
      "            for i_2_init, j_2_init, i_3_init in tir.grid(1, 4, 1):\n",
      "                for j_3_fused_init in tir.vectorized(2):\n",
      "                    with tir.block(\"Y_init\"):\n",
      "                        vi = tir.axis.spatial(1, i_3_init + i_2_init)\n",
      "                        vj = tir.axis.spatial(128, i_0_j_0_i_1_j_1_fused // 2 * 16 + i_0_j_0_i_1_j_1_fused % 2 * 8 + j_2_init * 2 + j_3_fused_init)\n",
      "                        tir.reads()\n",
      "                        tir.writes(Y[vi, vj])\n",
      "                        tir.block_attr({\"meta_schedule.tiling_structure\":\"SSRSRS\"})\n",
      "                        Y[vi, vj] = tir.float32(0)\n",
      "            for k_0, i_2, j_2, k_1, i_3 in tir.grid(49, 1, 4, 16, 1):\n",
      "                for j_3_fused in tir.vectorized(2):\n",
      "                    with tir.block(\"Y_update\"):\n",
      "                        vi = tir.axis.spatial(1, i_3 + i_2)\n",
      "                        vj = tir.axis.spatial(128, i_0_j_0_i_1_j_1_fused // 2 * 16 + i_0_j_0_i_1_j_1_fused % 2 * 8 + j_2 * 2 + j_3_fused)\n",
      "                        vk = tir.axis.reduce(784, k_0 * 16 + k_1)\n",
      "                        tir.reads(Y[vi, vj], X[vi, vk], W[vj, vk])\n",
      "                        tir.writes(Y[vi, vj])\n",
      "                        tir.block_attr({\"meta_schedule.tiling_structure\":\"SSRSRS\"})\n",
      "                        Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
      "            for ax0 in tir.serial(1):\n",
      "                for ax1_fused in tir.vectorized(8):\n",
      "                    with tir.block(\"Z\"):\n",
      "                        vi = tir.axis.spatial(1, ax0)\n",
      "                        vj = tir.axis.spatial(128, i_0_j_0_i_1_j_1_fused // 2 * 16 + i_0_j_0_i_1_j_1_fused % 2 * 8 + ax1_fused)\n",
      "                        tir.reads(Y[vi, vj], B[vj])\n",
      "                        tir.writes(Z[vi, vj])\n",
      "                        Z[vi, vj] = Y[vi, vj] + B[vj]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "MyModuleWithParams2 = relax.transform.BindParams(\"main\", nd_params)(MyModuleMixture)\n",
    "new_func = sch_tuned_linear.mod[\"main\"].with_attr(\"global_symbol\", \"linear0\")\n",
    "gv = MyModuleWithParams2.get_global_var(\"linear0\")\n",
    "MyModuleWithParams2.update_func(gv, new_func)\n",
    "print(MyModuleWithParams2.script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModuleWithParams2 Prediction: Coat\n"
     ]
    }
   ],
   "source": [
    "ex = relax.vm.build(MyModuleWithParams2, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "\n",
    "nd_res = vm[\"main\"](data_nd)\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MyModuleWithParams2 Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModuleWithParams2 time-cost: 0.224305 ms\n"
     ]
    }
   ],
   "source": [
    "ftimer = vm.module.time_evaluator(\"main\", tvm.cpu(), number=50)\n",
    "\n",
    "print(\"MyModuleWithParams2 time-cost: %g ms\" % (ftimer(data_nd).mean * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二维卷积的优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, CI, H, W, CO, K = 2, 2, 1024, 1024, 3, 11\n",
    "OUT_H, OUT_W = H - K + 1, W - K + 1\n",
    "\n",
    "@tvm.script.ir_module\n",
    "class MyConv:\n",
    "    @T.prim_func\n",
    "    def conv(data: T.Buffer[(N, CI, 1024, 1024), \"float32\"],\n",
    "             weight: T.Buffer[(CO, CI, K, K), \"float32\"],\n",
    "             res: T.Buffer[(N, CO, OUT_H, OUT_W), \"float32\"]):\n",
    "        T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
    "        for N_ind, oc_ind, h_ind, w_ind, ci_ind, h_K_ind, w_K_ind in T.grid(N, CO, OUT_H, OUT_W, CI, K, K):\n",
    "            with T.block(\"res\"):\n",
    "                v_N_ind, v_oc_ind, v_h_ind, v_w_ind, v_ci_ind, v_h_K_ind, v_w_K_ind = T.axis.remap(\"SSSSRRR\", [N_ind, oc_ind, h_ind, w_ind, ci_ind, h_K_ind, w_K_ind])\n",
    "                with T.init():\n",
    "                    res[v_N_ind, v_oc_ind, v_h_ind, v_w_ind] = T.float32(0)\n",
    "                res[v_N_ind, v_oc_ind, v_h_ind, v_w_ind] = res[v_N_ind, v_oc_ind, v_h_ind, v_w_ind] + data[v_N_ind, v_ci_ind, v_h_K_ind + v_h_ind, v_w_K_ind + v_w_ind] * weight[v_oc_ind, v_ci_ind, v_h_K_ind, v_w_K_ind]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build 查看运行时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost of MyConv: 1339.849 ms\n"
     ]
    }
   ],
   "source": [
    "data_np = np.random.randn(N, CI, H, W).astype(\"float32\")\n",
    "weight_np = np.random.randn(CO, CI, K, K).astype(\"float32\")\n",
    "res_np = np.empty((N, CO, OUT_H, OUT_W), dtype=\"float32\")\n",
    "\n",
    "data_nd = tvm.nd.array(data_np)\n",
    "weight_nd = tvm.nd.array(weight_np)\n",
    "res_nd = tvm.nd.array(res_np)\n",
    "\n",
    "lib = tvm.build(MyConv, target=\"llvm\")\n",
    "time_eval = lib.time_evaluator(\"main\", tvm.cpu())\n",
    "\n",
    "print(\"Time cost of MyConv: %.3f ms\" % (time_eval(data_nd, weight_nd, res_nd).mean * 1000))\n",
    "# print(time_eval(data_nd, weight_nd, res_nd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 14:55:17.581 INFO Logging directory: ./tune_tmp/logs\n",
      "2022-07-20 14:55:17.586 INFO Logging directory: ./tune_tmp/logs\n",
      "2022-07-20 14:55:17.587 INFO Working directory: ./tune_tmp\n",
      "2022-07-20 14:55:17.588 INFO Creating JSONDatabase. Workload at: ./tune_tmp/database_workload.json. Tuning records at: ./tune_tmp/database_tuning_record.json\n",
      "2022-07-20 14:55:17.590 INFO LocalBuilder: max_workers = 48\n",
      "2022-07-20 14:55:18.305 INFO LocalRunner: max_workers = 1\n",
      "2022-07-20 14:55:19.012 INFO Initializing Task #0: \"main\"\n",
      "2022-07-20 14:55:19.242 INFO \n",
      " ID | Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated \n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 2985881184 |      1 |            N/A |          N/A |                   N/A |      0 |            \n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 0\n",
      "Total latency (us): 0\n",
      "\n",
      "2022-07-20 14:55:19.244 INFO Scheduler picks Task #0: \"main\"\n",
      "2022-07-20 14:55:27.849 INFO Sending 63 sample(s) to builder\n",
      "2022-07-20 14:55:48.534 INFO Sending 63 sample(s) to runner\n",
      "2022-07-20 14:56:32.693 INFO [Updated] Task #0: \"main\"\n",
      " ID | Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated \n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 2985881184 |      1 |       218.9784 |   13635.5056 |            13635.5056 |     63 |            \n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 63\n",
      "Total latency (us): 13635.5\n",
      "\n",
      "2022-07-20 14:56:32.695 INFO Scheduler picks Task #0: \"main\"\n",
      "2022-07-20 14:56:41.131 INFO Sending 1 sample(s) to builder\n",
      "2022-07-20 14:56:42.970 INFO Sending 1 sample(s) to runner\n",
      "2022-07-20 14:56:44.201 INFO [Updated] Task #0: \"main\"\n",
      " ID | Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated \n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 2985881184 |      1 |       218.9784 |   13635.5056 |            13635.5056 |     64 |            \n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 64\n",
      "Total latency (us): 13635.5\n",
      "\n",
      "2022-07-20 14:56:44.202 INFO Task #0 has finished. Remaining task(s): 0\n",
      "2022-07-20 14:56:44.311 INFO Saved XGBModel to ./tune_tmp/cost_model.xgb\n"
     ]
    }
   ],
   "source": [
    "sch_tuned = ms.tune_tir(\n",
    "    mod=MyConv,\n",
    "    target=\"llvm --num-cores=1\",\n",
    "    config=ms.TuneConfig(\n",
    "      max_trials_global=64,\n",
    "      num_trials_per_iter=64,\n",
    "    ),\n",
    "    work_dir=work_dir,\n",
    "    task_name=\"main\",\n",
    ")\n",
    "shutil.rmtree(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost of optimized MyConv: 20.052 ms\n"
     ]
    }
   ],
   "source": [
    "lib = tvm.build(sch_tuned.mod)\n",
    "time_eval = lib.time_evaluator(\"main\", tvm.cpu())\n",
    "\n",
    "print(\"Time cost of optimized MyConv: %.3f ms\" % (time_eval(data_nd, weight_nd, res_nd).mean * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0 = sch.get_block(name=\"res\", func_name=\"main\")\n",
      "b1 = sch.get_block(name=\"root\", func_name=\"main\")\n",
      "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")\n",
      "l2, l3, l4, l5, l6, l7, l8 = sch.get_loops(block=b0)\n",
      "v9, v10, v11, v12 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])\n",
      "l13, l14, l15, l16 = sch.split(loop=l2, factors=[v9, v10, v11, v12])\n",
      "v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 3])\n",
      "l21, l22, l23, l24 = sch.split(loop=l3, factors=[v17, v18, v19, v20])\n",
      "v25, v26, v27, v28 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[338, 1, 3, 1])\n",
      "l29, l30, l31, l32 = sch.split(loop=l4, factors=[v25, v26, v27, v28])\n",
      "v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[13, 1, 13, 6])\n",
      "l37, l38, l39, l40 = sch.split(loop=l5, factors=[v33, v34, v35, v36])\n",
      "v41, v42 = sch.sample_perfect_tile(loop=l6, n=2, max_innermost_factor=64, decision=[2, 1])\n",
      "l43, l44 = sch.split(loop=l6, factors=[v41, v42])\n",
      "v45, v46 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[11, 1])\n",
      "l47, l48 = sch.split(loop=l7, factors=[v45, v46])\n",
      "v49, v50 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 11])\n",
      "l51, l52 = sch.split(loop=l8, factors=[v49, v50])\n",
      "sch.reorder(l13, l21, l29, l37, l14, l22, l30, l38, l43, l47, l51, l15, l23, l31, l39, l44, l48, l52, l16, l24, l32, l40)\n",
      "b53 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope=\"global\")\n",
      "sch.reverse_compute_at(block=b53, loop=l37, preserve_unit_loops=True)\n",
      "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.parallel\", ann_val=16)\n",
      "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.vectorize\", ann_val=64)\n",
      "v54 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)\n",
      "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v54)\n",
      "sch.enter_postproc()\n",
      "b55 = sch.get_block(name=\"root\", func_name=\"main\")\n",
      "sch.unannotate(block_or_loop=b55, ann_key=\"meta_schedule.parallel\")\n",
      "sch.unannotate(block_or_loop=b55, ann_key=\"meta_schedule.vectorize\")\n",
      "sch.unannotate(block_or_loop=b55, ann_key=\"meta_schedule.unroll_explicit\")\n",
      "b56, b57 = sch.get_child_blocks(b55)\n",
      "l58, l59, l60, l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b56)\n",
      "l80 = sch.fuse(l58, l59, l60)\n",
      "sch.parallel(loop=l80)\n",
      "l81 = sch.fuse(l79)\n",
      "sch.vectorize(loop=l81)\n",
      "sch.annotate(block_or_loop=l80, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)\n",
      "sch.annotate(block_or_loop=l80, ann_key=\"pragma_unroll_explicit\", ann_val=1)\n",
      "l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b57)\n",
      "sch.annotate(block_or_loop=l82, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)\n",
      "sch.annotate(block_or_loop=l82, ann_key=\"pragma_unroll_explicit\", ann_val=1)\n",
      "b88 = sch.get_block(name=\"res\", func_name=\"main\")\n",
      "l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b88)\n",
      "b109 = sch.decompose_reduction(block=b88, loop=l95)\n"
     ]
    }
   ],
   "source": [
    "print(sch_tuned.trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @tir.prim_func\n",
      "    def main(data: tir.Buffer[(1, 1, 1024, 1024), \"float32\"], weight: tir.Buffer[(2, 1, 7, 7), \"float32\"], res: tir.Buffer[(1, 2, 1018, 1018), \"float32\"]) -> None:\n",
      "        # function attr dict\n",
      "        tir.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        # body\n",
      "        # with tir.block(\"root\")\n",
      "        for N_ind_0_oc_ind_0_h_ind_0_fused in tir.parallel(509, annotations={\"pragma_auto_unroll_max_step\":512, \"pragma_unroll_explicit\":1}):\n",
      "            for w_ind_0, N_ind_1, oc_ind_1, h_ind_1, w_ind_1 in tir.grid(1, 1, 2, 1, 1018):\n",
      "                for N_ind_2_init, oc_ind_2_init, h_ind_2_init, w_ind_2_init, N_ind_3_init, oc_ind_3_init, h_ind_3_init, w_ind_3_init in tir.grid(1, 1, 1, 1, 1, 1, 2, 1):\n",
      "                    with tir.block(\"res_init\"):\n",
      "                        v_N_ind = tir.axis.spatial(1, N_ind_3_init + N_ind_2_init + N_ind_1 + 0)\n",
      "                        v_oc_ind = tir.axis.spatial(2, 0 * 2 + oc_ind_1 + oc_ind_2_init + oc_ind_3_init)\n",
      "                        v_h_ind = tir.axis.spatial(1018, (N_ind_0_oc_ind_0_h_ind_0_fused % 509 + h_ind_1 + h_ind_2_init) * 2 + h_ind_3_init)\n",
      "                        v_w_ind = tir.axis.spatial(1018, w_ind_0 * 1018 + w_ind_1 + w_ind_2_init + w_ind_3_init)\n",
      "                        tir.reads()\n",
      "                        tir.writes(res[v_N_ind, v_oc_ind, v_h_ind, v_w_ind])\n",
      "                        tir.block_attr({\"meta_schedule.tiling_structure\":\"SSRSRS\"})\n",
      "                        res[v_N_ind, v_oc_ind, v_h_ind, v_w_ind] = tir.float32(0)\n",
      "                for ci_ind_0, h_K_ind_0, w_K_ind_0, N_ind_2, oc_ind_2, h_ind_2, w_ind_2, ci_ind_1, h_K_ind_1, w_K_ind_1, N_ind_3, oc_ind_3, h_ind_3, w_ind_3 in tir.grid(1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1):\n",
      "                    with tir.block(\"res_update\"):\n",
      "                        v_N_ind = tir.axis.spatial(1, N_ind_3 + N_ind_2 + N_ind_1 + 0)\n",
      "                        v_oc_ind = tir.axis.spatial(2, 0 * 2 + oc_ind_1 + oc_ind_2 + oc_ind_3)\n",
      "                        v_h_ind = tir.axis.spatial(1018, (N_ind_0_oc_ind_0_h_ind_0_fused % 509 + h_ind_1 + h_ind_2) * 2 + h_ind_3)\n",
      "                        v_w_ind = tir.axis.spatial(1018, w_ind_0 * 1018 + w_ind_1 + w_ind_2 + w_ind_3)\n",
      "                        v_ci_ind = tir.axis.reduce(1, ci_ind_0 + ci_ind_1)\n",
      "                        v_h_K_ind = tir.axis.reduce(7, h_K_ind_0 + h_K_ind_1)\n",
      "                        v_w_K_ind = tir.axis.reduce(7, w_K_ind_0 + w_K_ind_1)\n",
      "                        tir.reads(res[v_N_ind, v_oc_ind, v_h_ind, v_w_ind], data[v_N_ind, v_ci_ind, v_h_K_ind + v_h_ind, v_w_K_ind + v_w_ind], weight[v_oc_ind, v_ci_ind, v_h_K_ind, v_w_K_ind])\n",
      "                        tir.writes(res[v_N_ind, v_oc_ind, v_h_ind, v_w_ind])\n",
      "                        tir.block_attr({\"meta_schedule.tiling_structure\":\"SSRSRS\"})\n",
      "                        res[v_N_ind, v_oc_ind, v_h_ind, v_w_ind] = res[v_N_ind, v_oc_ind, v_h_ind, v_w_ind] + data[v_N_ind, v_ci_ind, v_h_K_ind + v_h_ind, v_w_K_ind + v_w_ind] * weight[v_oc_ind, v_ci_ind, v_h_K_ind, v_w_K_ind]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(sch_tuned.mod.script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mlc-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a537d536684414c640a606739ee5e008de51f3cfc4afd56de838724fee6bb8e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
